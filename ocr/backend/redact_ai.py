import argparse
import re
import math
from typing import List, Tuple, Dict, Any
import sys
from pathlib import Path
import logging

# Set up logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# --- Dependencies with Fallback ---
try:
    import pytesseract
    from pytesseract import Output
    from PIL import Image
    import cv2
    import numpy as np
    HAS_DEPENDENCIES = True
except ImportError:
    HAS_DEPENDENCIES = False
    logger.error("Required libraries (pytesseract, OpenCV, Pillow, numpy) not found. Please install them.")
    sys.exit(1)

# --- Global Configurations ---
TEMPLATES = {
    "aadhaar": {
        "name": {'x': 0.12, 'y': 0.22, 'w': 0.6, 'h': 0.08, 'label': 'Name'},
        "aadhaar_number": {'x': 0.12, 'y': 0.34, 'w': 0.5, 'h': 0.08, 'label': 'Aadhaar Number'},
        "address": {'x': 0.12, 'y': 0.46, 'w': 0.7, 'h': 0.12, 'label': 'Address'},
        "dob": {'x': 0.12, 'y': 0.28, 'w': 0.4, 'h': 0.07, 'label': 'Date of Birth'},
    },
    # Make sure aadhar (alternative spelling) has the same template as aadhaar
    "aadhar": {
        "name": {'x': 0.12, 'y': 0.22, 'w': 0.6, 'h': 0.08, 'label': 'Name'},
        "aadhaar_number": {'x': 0.12, 'y': 0.34, 'w': 0.5, 'h': 0.08, 'label': 'Aadhaar Number'},
        "address": {'x': 0.12, 'y': 0.46, 'w': 0.7, 'h': 0.12, 'label': 'Address'},
        "dob": {'x': 0.12, 'y': 0.28, 'w': 0.4, 'h': 0.07, 'label': 'Date of Birth'},
    },
    "pan": {
        "pan_number": {'x': 0.08, 'y': 0.34, 'w': 0.5, 'h': 0.09, 'label': 'PAN'},
        "name": {'x': 0.08, 'y': 0.2, 'w': 0.7, 'h': 0.09, 'label': 'Name'},
        "dob": {'x': 0.08, 'y': 0.26, 'w': 0.5, 'h': 0.08, 'label': 'Date of Birth'},
    },
    "passport": {
        "name": {'x': 0.12, 'y': 0.18, 'w': 0.6, 'h': 0.07, 'label': 'Name'},
        "passport_number": {'x': 0.12, 'y': 0.28, 'w': 0.45, 'h': 0.07, 'label': 'Passport Number'},
        "nationality": {'x': 0.12, 'y': 0.36, 'w': 0.5, 'h': 0.06, 'label': 'Nationality'},
        "dob": {'x': 0.12, 'y': 0.42, 'w': 0.4, 'h': 0.06, 'label': 'Date of Birth'},
    }
}

# Define language-specific patterns and keywords
LANGUAGE_CONFIGS = {
    # English
    "eng": {
        "name_keywords": {"name", "candidate name", "student name", "holder", "cardholder", "full name"},
        "address_keywords": {"address", "residential", "residence", "permanent", "house", "street", "village", "city", "state", "pincode", "pin code"},
        "register_keywords": {"register", "regno", "reg.", "reg", "register no", "register number", "reg number", "reg num"}
    },
    # Tamil
    "tam": {
        "name_keywords": {"‡Æ™‡ØÜ‡ÆØ‡Æ∞‡Øç", "‡ÆÆ‡ØÅ‡Æ¥‡ØÅ‡Æ™‡Øç‡Æ™‡ØÜ‡ÆØ‡Æ∞‡Øç", "‡ÆÆ‡Ææ‡Æ£‡Æµ‡Æ∞‡Øç ‡Æ™‡ØÜ‡ÆØ‡Æ∞‡Øç", "‡Æµ‡Øà‡Æ§‡Øç‡Æ§‡Æø‡Æ∞‡ØÅ‡Æ™‡Øç‡Æ™‡Æµ‡Æ∞‡Øç ‡Æ™‡ØÜ‡ÆØ‡Æ∞‡Øç"},
        "address_keywords": {"‡ÆÆ‡ØÅ‡Æï‡Æµ‡Æ∞‡Æø", "‡Æµ‡ØÄ‡Æü‡Øç‡Æü‡ØÅ ‡ÆÆ‡ØÅ‡Æï‡Æµ‡Æ∞‡Æø", "‡Æ§‡Øä‡Æü‡Æ∞‡Øç‡Æ™‡ØÅ ‡ÆÆ‡ØÅ‡Æï‡Æµ‡Æ∞‡Æø", "‡Æ®‡Æø‡Æ∞‡Æ®‡Øç‡Æ§‡Æ∞ ‡ÆÆ‡ØÅ‡Æï‡Æµ‡Æ∞‡Æø", "‡Æµ‡ØÄ‡Æü‡ØÅ", "‡Æ§‡ØÜ‡Æ∞‡ØÅ", "‡Æä‡Æ∞‡Øç", "‡ÆÆ‡Ææ‡Æµ‡Æü‡Øç‡Æü‡ÆÆ‡Øç", "‡ÆÆ‡Ææ‡Æ®‡Æø‡Æ≤‡ÆÆ‡Øç", "‡ÆÖ‡Æû‡Øç‡Æö‡Æ≤‡Øç ‡Æï‡ØÅ‡Æ±‡Æø‡ÆØ‡ØÄ‡Æü‡ØÅ"},
        "register_keywords": {"‡Æ™‡Æ§‡Æø‡Æµ‡ØÅ ‡Æé‡Æ£‡Øç", "‡Æ™‡Æ§‡Æø‡Æµ‡ØÜ‡Æ£‡Øç", "‡Æ§‡Øä‡Æü‡Æ∞‡Øç ‡Æé‡Æ£‡Øç"}
    },
    # Kannada
    "kan": {
        "name_keywords": {"‡≤π‡≥Ü‡≤∏‡≤∞‡≥Å", "‡≤™‡≥Ç‡≤∞‡≥ç‡≤£ ‡≤π‡≥Ü‡≤∏‡≤∞‡≥Å", "‡≤µ‡≤ø‡≤¶‡≥ç‡≤Ø‡≤æ‡≤∞‡≥ç‡≤•‡≤ø‡≤Ø ‡≤π‡≥Ü‡≤∏‡≤∞‡≥Å", "‡≤ï‡≤æ‡≤∞‡≥ç‡≤°‡≥ç ‡≤π‡≥ä‡≤Ç‡≤¶‡≤ø‡≤∞‡≥Å‡≤µ‡≤µ‡≤∞ ‡≤π‡≥Ü‡≤∏‡≤∞‡≥Å"},
        "address_keywords": {"‡≤µ‡≤ø‡≤≥‡≤æ‡≤∏", "‡≤®‡≤ø‡≤µ‡≤æ‡≤∏", "‡≤∂‡≤æ‡≤∂‡≥ç‡≤µ‡≤§ ‡≤µ‡≤ø‡≤≥‡≤æ‡≤∏", "‡≤Æ‡≤®‡≥Ü", "‡≤∞‡≤∏‡≥ç‡≤§‡≥Ü", "‡≤ó‡≥ç‡≤∞‡≤æ‡≤Æ", "‡≤®‡≤ó‡≤∞", "‡≤ú‡≤ø‡≤≤‡≥ç‡≤≤‡≥Ü", "‡≤∞‡≤æ‡≤ú‡≥ç‡≤Ø", "‡≤™‡≤ø‡≤®‡≥ç ‡≤ï‡≥ã‡≤°‡≥ç"},
        "register_keywords": {"‡≤®‡≥ã‡≤Ç‡≤¶‡≤£‡≤ø ‡≤∏‡≤Ç‡≤ñ‡≥ç‡≤Ø‡≥Ü", "‡≤∞‡≤ø‡≤ú‡≤ø‡≤∏‡≥ç‡≤ü‡≤∞‡≥ç ‡≤∏‡≤Ç‡≤ñ‡≥ç‡≤Ø‡≥Ü", "‡≤ï‡≥ç‡≤∞‡≤Æ ‡≤∏‡≤Ç‡≤ñ‡≥ç‡≤Ø‡≥Ü"}
    },
    # Hindi
    "hin": {
        "name_keywords": {"‡§®‡§æ‡§Æ", "‡§™‡•Ç‡§∞‡§æ ‡§®‡§æ‡§Æ", "‡§õ‡§æ‡§§‡•ç‡§∞ ‡§ï‡§æ ‡§®‡§æ‡§Æ", "‡§ï‡§æ‡§∞‡•ç‡§°‡§ß‡§æ‡§∞‡§ï ‡§ï‡§æ ‡§®‡§æ‡§Æ"},
        "address_keywords": {"‡§™‡§§‡§æ", "‡§®‡§ø‡§µ‡§æ‡§∏ ‡§∏‡•ç‡§•‡§æ‡§®", "‡§∏‡•ç‡§•‡§æ‡§Ø‡•Ä ‡§™‡§§‡§æ", "‡§ò‡§∞", "‡§Æ‡§æ‡§∞‡•ç‡§ó", "‡§ó‡§æ‡§Å‡§µ", "‡§∂‡§π‡§∞", "‡§ú‡§ø‡§≤‡§æ", "‡§∞‡§æ‡§ú‡•ç‡§Ø", "‡§™‡§ø‡§® ‡§ï‡•ã‡§°"},
        "register_keywords": {"‡§™‡§Ç‡§ú‡•Ä‡§ï‡§∞‡§£ ‡§∏‡§Ç‡§ñ‡•ç‡§Ø‡§æ", "‡§∞‡§ú‡§ø‡§∏‡•ç‡§ü‡§∞ ‡§®‡§Ç‡§¨‡§∞", "‡§ï‡•ç‡§∞‡§Æ ‡§∏‡§Ç‡§ñ‡•ç‡§Ø‡§æ"}
    },
    # Telugu
    "tel": {
        "name_keywords": {"‡∞™‡±á‡∞∞‡±Å", "‡∞™‡±Ç‡∞∞‡±ç‡∞§‡∞ø ‡∞™‡±á‡∞∞‡±Å", "‡∞µ‡∞ø‡∞¶‡±ç‡∞Ø‡∞æ‡∞∞‡±ç‡∞•‡∞ø ‡∞™‡±á‡∞∞‡±Å", "‡∞ï‡∞æ‡∞∞‡±ç‡∞°‡±Å ‡∞π‡±ã‡∞≤‡±ç‡∞°‡∞∞‡±ç ‡∞™‡±á‡∞∞‡±Å"},
        "address_keywords": {"‡∞ö‡∞ø‡∞∞‡±Å‡∞®‡∞æ‡∞Æ‡∞æ", "‡∞®‡∞ø‡∞µ‡∞æ‡∞∏ ‡∞ö‡∞ø‡∞∞‡±Å‡∞®‡∞æ‡∞Æ‡∞æ", "‡∞∏‡±ç‡∞•‡∞ø‡∞∞ ‡∞ö‡∞ø‡∞∞‡±Å‡∞®‡∞æ‡∞Æ‡∞æ", "‡∞á‡∞≤‡±ç‡∞≤‡±Å", "‡∞∞‡±ã‡∞°‡±ç‡∞°‡±Å", "‡∞ó‡±ç‡∞∞‡∞æ‡∞Æ‡∞Ç", "‡∞®‡∞ó‡∞∞‡∞Ç", "‡∞ú‡∞ø‡∞≤‡±ç‡∞≤‡∞æ", "‡∞∞‡∞æ‡∞∑‡±ç‡∞ü‡±ç‡∞∞‡∞Ç", "‡∞™‡∞ø‡∞®‡±ç ‡∞ï‡±ã‡∞°‡±ç"},
        "register_keywords": {"‡∞®‡∞Æ‡±ã‡∞¶‡±Å ‡∞∏‡∞Ç‡∞ñ‡±ç‡∞Ø", "‡∞∞‡∞ø‡∞ú‡∞ø‡∞∏‡±ç‡∞ü‡∞∞‡±ç ‡∞®‡∞Ç‡∞¨‡∞∞‡±ç", "‡∞ï‡±ç‡∞∞‡∞Æ ‡∞∏‡∞Ç‡∞ñ‡±ç‡∞Ø"}
    },
    # Malayalam
    "mal": {
        "name_keywords": {"‡¥™‡µá‡¥∞‡µç", "‡¥Æ‡µÅ‡¥¥‡µÅ‡¥µ‡µª ‡¥™‡µá‡¥∞‡µç", "‡¥µ‡¥ø‡¥¶‡µç‡¥Ø‡¥æ‡µº‡¥§‡µç‡¥•‡¥ø‡¥Ø‡µÅ‡¥ü‡µÜ ‡¥™‡µá‡¥∞‡µç", "‡¥ï‡¥æ‡µº‡¥°‡µç ‡¥â‡¥ü‡¥Æ‡¥Ø‡µÅ‡¥ü‡µÜ ‡¥™‡µá‡¥∞‡µç"},
        "address_keywords": {"‡¥µ‡¥ø‡¥≤‡¥æ‡¥∏‡¥Ç", "‡¥§‡¥æ‡¥Æ‡¥∏ ‡¥µ‡¥ø‡¥≤‡¥æ‡¥∏‡¥Ç", "‡¥∏‡µç‡¥•‡¥ø‡¥∞ ‡¥µ‡¥ø‡¥≤‡¥æ‡¥∏‡¥Ç", "‡¥µ‡µÄ‡¥ü‡µç", "‡¥§‡µÜ‡¥∞‡µÅ‡¥µ‡µç", "‡¥ó‡µç‡¥∞‡¥æ‡¥Æ‡¥Ç", "‡¥®‡¥ó‡¥∞‡¥Ç", "‡¥ú‡¥ø‡¥≤‡µç‡¥≤", "‡¥∏‡¥Ç‡¥∏‡µç‡¥•‡¥æ‡¥®‡¥Ç", "‡¥™‡¥ø‡µª ‡¥ï‡µã‡¥°‡µç"},
        "register_keywords": {"‡¥∞‡¥ú‡¥ø‡¥∏‡µç‡¥ü‡µç‡¥∞‡µá‡¥∑‡µª ‡¥®‡¥Æ‡µç‡¥™‡µº", "‡¥∞‡¥ú‡¥ø‡¥∏‡µç‡¥±‡µç‡¥±‡µº ‡¥®‡¥Æ‡µç‡¥™‡µº", "‡¥ï‡µç‡¥∞‡¥Æ ‡¥®‡¥Æ‡µç‡¥™‡µº"}
    }
}

# Common patterns that work across languages
AADHAAR_RE = re.compile(r"\b\d{4}\s?\d{4}\s?\d{4}\b")
PAN_RE = re.compile(r"\b[A-Z]{5}\d{4}[A-Z]\b")
DATE_RE = re.compile(r"\b(?:\d{1,2}[-/\.]\d{1,2}[-/\.]\d{2,4}|(?:\d{4}[-/\.]\d{1,2}[-/\.]\d{1,2}))\b")
# Default English keywords for backward compatibility
NAME_KWS = LANGUAGE_CONFIGS["eng"]["name_keywords"]
REGISTER_KWS = LANGUAGE_CONFIGS["eng"]["register_keywords"]

# Keywords that should NOT be redacted (official headers, etc.)
NON_SENSITIVE_KEYWORDS = {
    # English
    "government of india", "govt of india", "government", "unique identification", "uidai", "issued by", "verify", 
    "signature", "male", "female", "gender", "help", "toll free", "aadhaar", "identification", "authority",
    # Hindi
    "‡§≠‡§æ‡§∞‡§§ ‡§∏‡§∞‡§ï‡§æ‡§∞", "‡§∏‡§∞‡§ï‡§æ‡§∞", "‡§™‡§π‡§ö‡§æ‡§®", "‡§™‡•ç‡§∞‡§æ‡§ß‡§ø‡§ï‡§∞‡§£", "‡§ú‡§æ‡§∞‡•Ä ‡§ï‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ", "‡§∏‡§§‡•ç‡§Ø‡§æ‡§™‡§ø‡§§", "‡§™‡•Å‡§∞‡•Å‡§∑", "‡§Æ‡§π‡§ø‡§≤‡§æ", "‡§≤‡§ø‡§Ç‡§ó", "‡§Æ‡§¶‡§¶", "‡§ü‡•ã‡§≤ ‡§´‡•ç‡§∞‡•Ä",
    # Tamil
    "‡Æá‡Æ®‡Øç‡Æ§‡Æø‡ÆØ ‡ÆÖ‡Æ∞‡Æö‡ØÅ", "‡ÆÖ‡Æ∞‡Æö‡ØÅ", "‡ÆÖ‡Æü‡Øà‡ÆØ‡Ææ‡Æ≥‡ÆÆ‡Øç", "‡ÆÜ‡Æ£‡Øà‡ÆØ‡ÆÆ‡Øç", "‡Æµ‡Æ¥‡Æô‡Øç‡Æï‡Æ™‡Øç‡Æ™‡Æü‡Øç‡Æü‡Æ§‡ØÅ", "‡Æö‡Æ∞‡Æø‡Æ™‡Ææ‡Æ∞‡Øç‡Æï‡Øç‡Æï‡Æµ‡ØÅ‡ÆÆ‡Øç", "‡ÆÜ‡Æ£‡Øç", "‡Æ™‡ØÜ‡Æ£‡Øç", "‡Æ™‡Ææ‡Æ≤‡Æø‡Æ©‡ÆÆ‡Øç", "‡Æâ‡Æ§‡Æµ‡Æø", "‡Æï‡Æü‡Øç‡Æü‡Æ£‡ÆÆ‡Æø‡Æ≤‡Øç‡Æ≤‡Ææ",
    # Kannada
    "‡≤≠‡≤æ‡≤∞‡≤§ ‡≤∏‡≤∞‡≥ç‡≤ï‡≤æ‡≤∞", "‡≤∏‡≤∞‡≥ç‡≤ï‡≤æ‡≤∞", "‡≤ó‡≥Å‡≤∞‡≥Å‡≤§‡≤ø‡≤®", "‡≤™‡≥ç‡≤∞‡≤æ‡≤ß‡≤ø‡≤ï‡≤æ‡≤∞", "‡≤®‡≥Ä‡≤°‡≤ø‡≤¶", "‡≤™‡≤∞‡≤ø‡≤∂‡≥Ä‡≤≤‡≤ø‡≤∏‡≤ø", "‡≤™‡≥Å‡≤∞‡≥Å‡≤∑", "‡≤Æ‡≤π‡≤ø‡≤≥‡≥Ü", "‡≤≤‡≤ø‡≤Ç‡≤ó", "‡≤∏‡≤π‡≤æ‡≤Ø", "‡≤ü‡≥ã‡≤≤‡≥ç ‡≤´‡≥ç‡≤∞‡≥Ä",
    # Telugu
    "‡∞≠‡∞æ‡∞∞‡∞§ ‡∞™‡±ç‡∞∞‡∞≠‡±Å‡∞§‡±ç‡∞µ‡∞Ç", "‡∞™‡±ç‡∞∞‡∞≠‡±Å‡∞§‡±ç‡∞µ‡∞Ç", "‡∞ó‡±Å‡∞∞‡±ç‡∞§‡∞ø‡∞Ç‡∞™‡±Å", "‡∞Ö‡∞•‡∞æ‡∞∞‡∞ø‡∞ü‡±Ä", "‡∞ú‡∞æ‡∞∞‡±Ä ‡∞ö‡±á‡∞Ø‡∞¨‡∞°‡∞ø‡∞Ç‡∞¶‡∞ø", "‡∞ß‡±É‡∞µ‡±Ä‡∞ï‡∞∞‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø", "‡∞™‡±Å‡∞∞‡±Å‡∞∑‡±Å‡∞°‡±Å", "‡∞∏‡±ç‡∞§‡±ç‡∞∞‡±Ä", "‡∞≤‡∞ø‡∞Ç‡∞ó‡∞Ç", "‡∞∏‡∞π‡∞æ‡∞Ø‡∞Ç", "‡∞ü‡±ã‡∞≤‡±ç ‡∞´‡±ç‡∞∞‡±Ä",
    # Malayalam
    "‡¥á‡¥®‡µç‡¥§‡µç‡¥Ø ‡¥∏‡µº‡¥ï‡µç‡¥ï‡¥æ‡µº", "‡¥∏‡µº‡¥ï‡µç‡¥ï‡¥æ‡µº", "‡¥§‡¥ø‡¥∞‡¥ø‡¥ö‡µç‡¥ö‡¥±‡¥ø‡¥Ø‡µΩ", "‡¥Ö‡¥§‡µã‡¥±‡¥ø‡¥±‡µç‡¥±‡¥ø", "‡¥®‡µΩ‡¥ï‡¥ø‡¥Ø‡¥§‡µç", "‡¥™‡¥∞‡¥ø‡¥∂‡µã‡¥ß‡¥ø‡¥ï‡µç‡¥ï‡µÅ‡¥ï", "‡¥™‡µÅ‡¥∞‡µÅ‡¥∑‡µª", "‡¥∏‡µç‡¥§‡µç‡¥∞‡µÄ", "‡¥≤‡¥ø‡¥Ç‡¥ó‡¥Ç", "‡¥∏‡¥π‡¥æ‡¥Ø‡¥Ç", "‡¥ü‡µã‡µæ ‡¥´‡µç‡¥∞‡µÄ"
}

# --- Image Preprocessing Functions ---
def _auto_rotate(gray: np.ndarray) -> np.ndarray:
    """Estimate small skew and deskew using Hough lines."""
    edges = cv2.Canny(gray, 50, 150)
    lines = cv2.HoughLines(edges, 1, np.pi / 180, threshold=200)
    if lines is None:
        return gray
    angles = []
    for rho, theta in lines[:, 0]:
        angle = (theta - np.pi/2) * 180 / np.pi
        if -20 < angle < 20:
            angles.append(angle)
    if not angles:
        return gray
    median_angle = np.median(angles)
    h, w = gray.shape[:2]
    M = cv2.getRotationMatrix2D((w//2, h//2), median_angle, 1.0)
    return cv2.warpAffine(gray, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)

def preprocess_image_for_ocr(image_path: str, debug: bool = False) -> Tuple[np.ndarray, np.ndarray]:
    """Returns (original_color_bgr, processed_gray_for_ocr)"""
    orig = cv2.imread(image_path, cv2.IMREAD_COLOR)
    if orig is None:
        raise FileNotFoundError(f"Cannot read image: {image_path}")
    
    scale = 1.5 if max(orig.shape[:2]) < 1600 else 1.0
    if scale != 1.0:
        orig = cv2.resize(orig, None, fx=scale, fy=scale, interpolation=cv2.INTER_CUBIC)

    gray = cv2.cvtColor(orig, cv2.COLOR_BGR2GRAY)
    gray = cv2.bilateralFilter(gray, 7, 60, 60)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    gray = clahe.apply(gray)
    
    _, bin_otsu = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    adaptive = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                                     cv2.THRESH_BINARY, 31, 8)
    def textiness(img):
        cnts, _ = cv2.findContours(255 - img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        sizes = [cv2.contourArea(c) for c in cnts]
        return sum(1 for a in sizes if 20 < a < 10000)
    proc = bin_otsu if textiness(bin_otsu) >= textiness(adaptive) else adaptive
    
    proc = _auto_rotate(proc)
    proc = cv2.medianBlur(proc, 3)
    if debug:
        cv2.imwrite("debug_preprocessed.png", proc)
    return orig, proc

# --- OCR & Detection Functions ---
def _ocr_with_boxes(img_gray_or_bin: np.ndarray, lang: str) -> Dict[str, List[Any]]:
    config = "--oem 3 --psm 6"
    data = pytesseract.image_to_data(img_gray_or_bin, lang=lang, config=config, output_type=Output.DICT)
    return data

def _merge_boxes(boxes: List[Tuple[int, int, int, int]]) -> Tuple[int, int, int, int]:
    if not boxes:
        return (0, 0, 0, 0)
    xs = [x for x, y, w, h in boxes]
    ys = [y for x, y, w, h in boxes]
    xe = [x + w for x, y, w, h in boxes]
    ye = [y + h for x, y, w, h in boxes]
    return (min(xs), min(ys), max(xe) - min(xs), max(ye) - min(ys))

def _words_after_keyword(i: int, data: Dict[str, List[Any]], max_words: int = 4) -> Tuple[str, List[int]]:
    line = data['line_num'][i]
    indices = [j for j in range(i + 1, len(data['text'])) if data['line_num'][j] == line and data['text'][j].strip()]
    take = indices[:max_words]
    text = " ".join(data['text'][j] for j in take).strip()
    return text, take

def detect_entities_from_ocr(data: Dict[str, List[Any]], requested_fields: set, debug: bool = False, lang: str = "eng"):
    hits: Dict[str, List[Tuple[int, int, int, int]]] = {f: [] for f in requested_fields}
    words = [(w or "").strip() for w in data['text']]
    
    # Get language-specific keywords
    # Parse language code - if multi-language like "eng+tam", use first language
    primary_lang = lang.split('+')[0] if '+' in lang else lang
    # Fallback to English if language not in our configs
    if primary_lang not in LANGUAGE_CONFIGS:
        if debug:
            print(f"[DEBUG] Language '{primary_lang}' not in configs, using English as fallback")
        primary_lang = "eng"
        
    name_keywords = LANGUAGE_CONFIGS[primary_lang]["name_keywords"]
    address_keywords = LANGUAGE_CONFIGS[primary_lang]["address_keywords"]
    register_keywords = LANGUAGE_CONFIGS[primary_lang]["register_keywords"]
    
    if debug:
        print(f"[DEBUG] Using language: {primary_lang}")
        print(f"[DEBUG] Name keywords: {name_keywords}")
    
    # Pass 1: regex matches
    full_text = " ".join(words)
    starts = []
    text_builder = []
    for idx, w in enumerate(words):
        if not w:
            continue
        starts.append((len(" ".join(text_builder)), idx))
        text_builder.append(w)
    full_text = " ".join(text_builder)
    
    # Check if text contains non-sensitive terms that should be excluded
    def is_non_sensitive(text):
        text = text.lower()
        for term in NON_SENSITIVE_KEYWORDS:
            if term in text:
                return True
        return False

    # Detect Aadhaar numbers 
    if "aadhaar_number" in requested_fields:
        # More aggressive pattern to catch Aadhaar numbers even with OCR errors
        for m in AADHAAR_RE.finditer(full_text):
            token_idxs = []
            m_start, m_end = m.span()
            for start_char, idx in starts:
                w = (words[idx] or "").strip()
                end_char = start_char + len(w)
                if not (end_char < m_start or start_char > m_end):
                    token_idxs.append(idx)
            if token_idxs:
                boxes = [(data['left'][i], data['top'][i], data['width'][i], data['height'][i]) for i in token_idxs]
                hits["aadhaar_number"].append(_merge_boxes(boxes))
                
        # Also check for keywords like "Aadhaar", "‡§Ü‡§ß‡§æ‡§∞", etc. followed by digits
        aadhaar_keywords = {
            "aadhar", "aadhaar", "‡§Ü‡§ß‡§æ‡§∞", "‡ÆÜ‡Æ§‡Ææ‡Æ∞‡Øç", "‡≤Ü‡≤ß‡≤æ‡≤∞‡≥ç", "‡¥Ü‡¥ß‡¥æ‡µº", "‡∞Ü‡∞ß‡∞æ‡∞∞‡±ç"
        }
        for i, w in enumerate(lowered):
            if any(kw in w for kw in aadhaar_keywords):
                # Look for digits in next few words
                _, idxs = _words_after_keyword(i, data, max_words=4)
                if idxs:
                    # Look for digit patterns in those words
                    id_text = "".join([data['text'][j] for j in idxs])
                    if re.search(r'\d{4}', id_text):  # Even partial match is worth checking
                        boxes = [(data['left'][j], data['top'][j], data['width'][j], data['height'][j]) for j in idxs]
                        hits["aadhaar_number"].append(_merge_boxes(boxes))

    # Detect PAN numbers
    if "pan_number" in requested_fields:
        for m in PAN_RE.finditer(full_text):
            token_idxs = []
            m_start, m_end = m.span()
            for start_char, idx in starts:
                w = (words[idx] or "").strip()
                end_char = start_char + len(w)
                if not (end_char < m_start or start_char > m_end):
                    token_idxs.append(idx)
            if token_idxs:
                boxes = [(data['left'][i], data['top'][i], data['width'][i], data['height'][i]) for i in token_idxs]
                hits["pan_number"].append(_merge_boxes(boxes))
    
    # Detect dates (including DOB)
    if "dob" in requested_fields:
        for m in DATE_RE.finditer(full_text):
            token_idxs = []
            m_start, m_end = m.span()
            for start_char, idx in starts:
                w = (words[idx] or "").strip()
                end_char = start_char + len(w)
                if not (end_char < m_start or start_char > m_end):
                    token_idxs.append(idx)
            if token_idxs:
                boxes = [(data['left'][i], data['top'][i], data['width'][i], data['height'][i]) for i in token_idxs]
                hits["dob"].append(_merge_boxes(boxes))

    # Pass 2: keyword spans
    lowered = [(w or "").strip().lower() for w in data['text']]
    
    # Detect names
    if "name" in requested_fields:
        for i, w in enumerate(lowered):
            if any(kw in w for kw in name_keywords):
                _, idxs = _words_after_keyword(i, data, max_words=4)
                if idxs:
                    # Skip if the detected text is in our non-sensitive list
                    text = " ".join([data['text'][j] for j in idxs]).lower()
                    if not is_non_sensitive(text):
                        boxes = [(data['left'][j], data['top'][j], data['width'][j], data['height'][j]) for j in idxs]
                        hits["name"].append(_merge_boxes(boxes))
    
    # Detect address
    if "address" in requested_fields:
        for i, w in enumerate(lowered):
            if any(kw in w for kw in address_keywords):
                _, idxs = _words_after_keyword(i, data, max_words=10)  # Addresses are longer
                if idxs:
                    # Skip if the detected text is in our non-sensitive list
                    text = " ".join([data['text'][j] for j in idxs]).lower()
                    if not is_non_sensitive(text):
                        boxes = [(data['left'][j], data['top'][j], data['width'][j], data['height'][j]) for j in idxs]
                        hits["address"].append(_merge_boxes(boxes))

    # Detect registration numbers
    if "register_number" in requested_fields:
        for i, w in enumerate(lowered):
            if any(kw in w for kw in register_keywords):
                _, idxs = _words_after_keyword(i, data, max_words=2)
                if idxs:
                    # Skip if the detected text is in our non-sensitive list
                    text = " ".join([data['text'][j] for j in idxs]).lower()
                    if not is_non_sensitive(text):
                        boxes = [(data['left'][j], data['top'][j], data['width'][j], data['height'][j]) for j in idxs]
                        hits["register_number"].append(_merge_boxes(boxes))

    # Deduplicate
    for k in list(hits.keys()):
        uniq = []
        seen = set()
        for (x, y, w, h) in hits[k]:
            key = (x // 2, y // 2, w // 2, h // 2)
            if key not in seen:
                seen.add(key)
                uniq.append((x, y, w, h))
        hits[k] = uniq
    
    if debug:
        print("[DEBUG] Detected fields:")
        for field, boxes in hits.items():
            print(f"  {field}: {len(boxes)} boxes found")
    
    return hits

def draw_redactions(color_bgr: np.ndarray, boxes: List[Tuple[int, int, int, int]], style: str = "black"):
    for (x, y, w, h) in boxes:
        if style == "blur":
            roi = color_bgr[y:y + h, x:x + w]
            if roi.size == 0: continue
            roi = cv2.GaussianBlur(roi, (25, 25), 0)
            color_bgr[y:y + h, x:x + w] = roi
        elif style == "pixel":
            roi = color_bgr[y:y + h, x:x + w]
            if roi.size == 0: continue
            ph, pw = max(6, h // 12), max(6, w // 12)
            roi_small = cv2.resize(roi, (pw, ph), interpolation=cv2.INTER_LINEAR)
            roi_pix = cv2.resize(roi_small, (w, h), interpolation=cv2.INTER_NEAREST)
            color_bgr[y:y + h, x:x + w] = roi_pix
        elif style == "yellow":
            # Yellow highlight for temporary redaction
            cv2.rectangle(color_bgr, (x, y), (x + w, y + h), (0, 255, 255), thickness=-1)
        elif style == "red":
            # Red highlight for brush redaction
            cv2.rectangle(color_bgr, (x, y), (x + w, y + h), (0, 0, 255), thickness=-1)
        else:
            # Black by default for permanent redaction
            cv2.rectangle(color_bgr, (x, y), (x + w, y + h), (0, 0, 0), thickness=-1)

# --- Main Redaction Function ---
def redact_image(image_path: str, doc_type: str = "unknown",
                 permanent_fields: List[str] = None, temporary_fields: List[str] = None,
                 lang: str = "eng", debug: bool = False, style: str = "black") -> Image.Image:
    if permanent_fields is None: permanent_fields = []
    if temporary_fields is None: temporary_fields = []
    
    color_bgr, ocr_img = preprocess_image_for_ocr(image_path, debug=debug)
    h, w = color_bgr.shape[:2]
    req_fields = set([f.lower() for f in (permanent_fields + temporary_fields)])
    
    # Check if document type is Aadhar with alternate spelling
    if doc_type.lower() in ['aadhar', 'aadhaar']:
        doc_type_normalized = 'aadhaar'  # Normalize to one spelling
        # Always include Aadhaar number in requested fields for Aadhar cards
        req_fields.add('aadhaar_number')
    else:
        doc_type_normalized = doc_type.lower()

    # First try to detect fields using OCR for all document types
    data = _ocr_with_boxes(ocr_img, lang=lang)
    if debug:
        extracted = " ".join([t for t in data['text'] if t and t.strip()])
        print(f"\n[DEBUG] Raw Extracted Text ({lang}):\n", extracted, "\n")
        print(f"[DEBUG] Document type: {doc_type_normalized}")
        print(f"[DEBUG] Requested fields: {req_fields}")
    
    boxes_by_field = detect_entities_from_ocr(data, req_fields, debug=debug, lang=lang)
    
    # Process detected fields first
    fields_redacted = set()
    for field, boxes in boxes_by_field.items():
        if boxes:  # Only if we found boxes for this field
            redaction_style = "black" if field in permanent_fields else "yellow"
            draw_redactions(color_bgr, boxes, style=redaction_style)
            fields_redacted.add(field)
            if debug:
                print(f"[DEBUG] Applied OCR-detected redactions for {field}")
    
    # Fall back to template coordinates for fields that weren't detected
    if doc_type_normalized in TEMPLATES:
        template_fields = TEMPLATES[doc_type_normalized]
        for f in req_fields:
            if f in template_fields and f not in fields_redacted:
                box_norm = template_fields[f]
                x = int(box_norm['x'] * w)
                y = int(box_norm['y'] * h)
                width = int(box_norm['w'] * w)
                height = int(box_norm['h'] * h)
                redaction_style = "black" if f in permanent_fields else "yellow"
                draw_redactions(color_bgr, [(x, y, width, height)], style=redaction_style)
                if debug:
                    print(f"[DEBUG] Applied template-based redactions for {f}")
    
    # Special case for Aadhar cards - make sure aadhaar_number is always redacted
    # This is a fallback in case both OCR and template failed
    if doc_type_normalized == 'aadhaar' and 'aadhaar_number' in req_fields and 'aadhaar_number' not in fields_redacted:
        # Apply a wider redaction area for Aadhar number as a last resort
        center_y = int(h * 0.34)  # Typical location for Aadhar number
        redaction_style = "black" if 'aadhaar_number' in permanent_fields else "yellow"
        draw_redactions(color_bgr, [(int(w * 0.1), center_y, int(w * 0.8), int(h * 0.08))], style=redaction_style)
        if debug:
            print(f"[DEBUG] Applied fallback redaction for aadhaar_number")

    return Image.fromarray(cv2.cvtColor(color_bgr, cv2.COLOR_BGR2RGB))

# --- Function to process custom redactions ---
def apply_custom_redactions(image_path: str, redactions: List[dict], redaction_type: str = "temporary"):
    """Apply custom redactions to an image based on coordinates provided."""
    img = cv2.imread(image_path)
    if img is None:
        raise FileNotFoundError(f"Cannot read image: {image_path}")
    
    for redaction in redactions:
        pos = redaction.get('position', {})
        x = pos.get('x', 0)
        y = pos.get('y', 0)
        w = pos.get('width', 0)
        h = pos.get('height', 0)
        method = redaction.get('method', 'select')
        
        if x > 0 and y > 0 and w > 0 and h > 0:
            if redaction_type == 'permanent':
                # Black for permanent redaction
                cv2.rectangle(img, (x, y), (x + w, y + h), (0, 0, 0), -1)
            else:
                if method == 'brush':
                    # Yellow for temporary brush redaction
                    cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 255), -1)
                else:
                    # Gray for temporary selection redaction
                    cv2.rectangle(img, (x, y), (x + w, y + h), (192, 192, 192), -1)
    
    return img

# --- Command Line Interface (CLI) ---
if __name__ == "__main__":
    if not HAS_DEPENDENCIES:
        sys.exit(1)
        
    parser = argparse.ArgumentParser(
        description="RedactAI - Advanced document redaction\n",
        formatter_class=argparse.RawTextHelpFormatter
    )
    parser.add_argument("--image", required=True, help="Path to input image")
    parser.add_argument("--doc_type", default="unknown", help="aadhaar | pan | passport | unknown")
    parser.add_argument("--permanent_fields", nargs="*", default=[], help="Fields to redact permanently")
    parser.add_argument("--temporary_fields", nargs="*", default=[], help="Fields to redact temporarily")
    parser.add_argument("--output", default="redacted_output.jpg", help="Output file name")
    parser.add_argument("--lang", default="eng", help="Tesseract language (e.g. eng, eng+hin)")
    parser.add_argument("--style", default="black", choices=["black", "blur", "pixel"], help="Redaction style")
    parser.add_argument("--debug", action="store_true", help="Print OCR text and save debug image")

    args = parser.parse_args()
    
    try:
        img = redact_image(
            image_path=args.image,
            doc_type=args.doc_type,
            permanent_fields=args.permanent_fields,
            temporary_fields=args.temporary_fields,
            lang=args.lang,
            debug=args.debug,
            style=args.style
        )
        img.save(args.output)
        print(f"‚úÖ Redacted image saved to {args.output}")
        if args.debug:
            print("üß™ Saved preprocessing snapshot to debug_preprocessed.png.")
    except Exception as e:
        logger.error(f"An error occurred: {e}")
        sys.exit(1)
